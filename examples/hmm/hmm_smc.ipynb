{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eli/AnacondaProjects/combinators\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from combinators import lens, sampler, utils\n",
    "from combinators.inference import conditioning, resample\n",
    "from combinators.model import collections\n",
    "import examples.hmm.hmm as hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_params = {\n",
    "    'mu': (torch.arange(5, dtype=torch.float) * 2).expand(2, 5).t(),\n",
    "    'concentration': torch.ones(5, 2) * 2,\n",
    "    'rate': torch.ones(5, 2) * 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = sampler.importance_box('hmm_parameters', hmm.Parameters(5, 2, state_params), (1,), hmm.ParametersProposal(), lens.PRO(0), lens.PRO(4))\n",
    "hmm_step = sampler.importance_box('hmm_step', hmm.TransitionAndEmission(), (1,), hmm.TransitionProposal(), lens.PRO(4), lens.PRO(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = collections.sequential(hmm_step, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_model = prior >> chain\n",
    "hmm_sampler = sampler.compile(hmm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.filter(hmm_sampler)\n",
    "p, log_weight = sampler.trace(hmm_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = [p[k].value for k in p if 'z' in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([4]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([1]),\n",
       " tensor([4]),\n",
       " tensor([4]),\n",
       " tensor([1]),\n",
       " tensor([4]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([4]),\n",
       " tensor([0]),\n",
       " tensor([1]),\n",
       " tensor([1]),\n",
       " tensor([4]),\n",
       " tensor([0]),\n",
       " tensor([3]),\n",
       " tensor([2]),\n",
       " tensor([1]),\n",
       " tensor([4]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([1]),\n",
       " tensor([3]),\n",
       " tensor([1]),\n",
       " tensor([3]),\n",
       " tensor([4]),\n",
       " tensor([3]),\n",
       " tensor([2]),\n",
       " tensor([4]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([1]),\n",
       " tensor([3]),\n",
       " tensor([3]),\n",
       " tensor([1]),\n",
       " tensor([3]),\n",
       " tensor([1]),\n",
       " tensor([3]),\n",
       " tensor([3]),\n",
       " tensor([1]),\n",
       " tensor([3]),\n",
       " tensor([1]),\n",
       " tensor([3]),\n",
       " tensor([2]),\n",
       " tensor([1]),\n",
       " tensor([4])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [p[k].value for k in p if 'x' in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 7.5328, 12.6918]]),\n",
       " tensor([[3.5403, 1.3866]]),\n",
       " tensor([[ 2.8297, -0.2054]]),\n",
       " tensor([[ 1.9631, -0.1380]]),\n",
       " tensor([[ 0.8396, -0.5853]]),\n",
       " tensor([[ 7.4074, 10.8746]]),\n",
       " tensor([[8.7990, 9.9349]]),\n",
       " tensor([[1.7775, 0.2576]]),\n",
       " tensor([[ 5.4967, 12.2110]]),\n",
       " tensor([[ 3.5204, -0.1720]]),\n",
       " tensor([[1.2444, 1.3263]]),\n",
       " tensor([[ 2.7883, -2.0661]]),\n",
       " tensor([[ 8.7756, 16.4658]]),\n",
       " tensor([[2.6608, 0.4371]]),\n",
       " tensor([[ 1.8057, -2.3360]]),\n",
       " tensor([[-1.4781,  0.4416]]),\n",
       " tensor([[ 4.9871, 12.6439]]),\n",
       " tensor([[-0.1186,  1.7229]]),\n",
       " tensor([[6.5152, 8.5877]]),\n",
       " tensor([[2.6754, 4.3759]]),\n",
       " tensor([[ 0.8380, -1.0770]]),\n",
       " tensor([[9.2146, 5.6433]]),\n",
       " tensor([[2.9043, 0.7807]]),\n",
       " tensor([[2.2589, 0.5164]]),\n",
       " tensor([[-0.3089,  0.5315]]),\n",
       " tensor([[2.9178, 0.0752]]),\n",
       " tensor([[1.0121, 1.6633]]),\n",
       " tensor([[8.0800, 8.2057]]),\n",
       " tensor([[2.8460, 0.2995]]),\n",
       " tensor([[7.2104, 7.6419]]),\n",
       " tensor([[ 6.9215, 15.2308]]),\n",
       " tensor([[ 8.7435, 10.2405]]),\n",
       " tensor([[0.8680, 2.3731]]),\n",
       " tensor([[ 4.9715, 12.0816]]),\n",
       " tensor([[ 1.5856, -2.0624]]),\n",
       " tensor([[ 3.9987, -0.6573]]),\n",
       " tensor([[ 1.3955, -2.3637]]),\n",
       " tensor([[6.8602, 3.5467]]),\n",
       " tensor([[7.8231, 7.9523]]),\n",
       " tensor([[-0.9108,  1.3089]]),\n",
       " tensor([[ 6.2870, 12.3138]]),\n",
       " tensor([[ 5.0531, -0.1120]]),\n",
       " tensor([[6.5350, 6.6158]]),\n",
       " tensor([[5.6552, 8.2339]]),\n",
       " tensor([[3.1211, 3.6600]]),\n",
       " tensor([[ 6.9472, 10.0538]]),\n",
       " tensor([[-1.5730,  3.1851]]),\n",
       " tensor([[7.6935, 7.8635]]),\n",
       " tensor([[2.2086, 4.0549]]),\n",
       " tensor([[1.3443, 4.3346]])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_particles = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_params = {\n",
    "    'mu': (torch.arange(5, dtype=torch.float) * 2).expand(2, 5).t(),\n",
    "    'concentration': torch.ones(5, 2),\n",
    "    'rate': torch.ones(5, 2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = sampler.importance_box('hmm_parameters', hmm.Parameters(5, 2, inference_params), (num_particles,), hmm.ParametersProposal(), lens.PRO(0), lens.PRO(4))\n",
    "hmm_step = sampler.importance_box('hmm_step', hmm.TransitionAndEmission(), (num_particles,), hmm.TransitionProposal(), lens.PRO(4), lens.PRO(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = collections.sequential(hmm_step, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditioned_chain = conditioning.SequentialConditioner(hmm_step=xs)(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_inference = params >> conditioned_chain\n",
    "hmm_resampler = sampler.compile(hmm_inference)\n",
    "resample.hook_resampling(hmm_resampler, method='get', resampler_cls=resample.SystematicResampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.filter(hmm_resampler)\n",
    "p, log_weight = sampler.trace(hmm_resampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091, -740.4091, -740.4091,\n",
       "        -740.4091, -740.4091, -740.4091, -740.4091])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_zs = [p[k].value for k in p if 'z' in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = [(pr == tr).to(dtype=torch.float) for pr, tr in zip(inferred_zs, zs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMC percent accuracy at time 0: 100.000000\n",
      "SMC percent accuracy at time 1: 100.000000\n",
      "SMC percent accuracy at time 2: 0.000000\n",
      "SMC percent accuracy at time 3: 0.000000\n",
      "SMC percent accuracy at time 4: 100.000000\n",
      "SMC percent accuracy at time 5: 100.000000\n",
      "SMC percent accuracy at time 6: 100.000000\n",
      "SMC percent accuracy at time 7: 100.000000\n",
      "SMC percent accuracy at time 8: 0.000000\n",
      "SMC percent accuracy at time 9: 0.000000\n",
      "SMC percent accuracy at time 10: 0.000000\n",
      "SMC percent accuracy at time 11: 100.000000\n",
      "SMC percent accuracy at time 12: 100.000000\n",
      "SMC percent accuracy at time 13: 100.000000\n",
      "SMC percent accuracy at time 14: 100.000000\n",
      "SMC percent accuracy at time 15: 0.000000\n",
      "SMC percent accuracy at time 16: 100.000000\n",
      "SMC percent accuracy at time 17: 100.000000\n",
      "SMC percent accuracy at time 18: 83.600006\n",
      "SMC percent accuracy at time 19: 83.600006\n",
      "SMC percent accuracy at time 20: 100.000000\n",
      "SMC percent accuracy at time 21: 0.000000\n",
      "SMC percent accuracy at time 22: 0.000000\n",
      "SMC percent accuracy at time 23: 0.000000\n",
      "SMC percent accuracy at time 24: 83.600006\n",
      "SMC percent accuracy at time 25: 0.000000\n",
      "SMC percent accuracy at time 26: 83.600006\n",
      "SMC percent accuracy at time 27: 83.600006\n",
      "SMC percent accuracy at time 28: 100.000000\n",
      "SMC percent accuracy at time 29: 0.000000\n",
      "SMC percent accuracy at time 30: 100.000000\n",
      "SMC percent accuracy at time 31: 0.000000\n",
      "SMC percent accuracy at time 32: 0.000000\n",
      "SMC percent accuracy at time 33: 100.000000\n",
      "SMC percent accuracy at time 34: 90.800003\n",
      "SMC percent accuracy at time 35: 72.799995\n",
      "SMC percent accuracy at time 36: 0.000000\n",
      "SMC percent accuracy at time 37: 8.800000\n",
      "SMC percent accuracy at time 38: 28.799999\n",
      "SMC percent accuracy at time 39: 8.800000\n",
      "SMC percent accuracy at time 40: 0.000000\n",
      "SMC percent accuracy at time 41: 0.000000\n",
      "SMC percent accuracy at time 42: 44.000000\n",
      "SMC percent accuracy at time 43: 16.400000\n",
      "SMC percent accuracy at time 44: 11.200001\n",
      "SMC percent accuracy at time 45: 0.400000\n",
      "SMC percent accuracy at time 46: 0.000000\n",
      "SMC percent accuracy at time 47: 82.800003\n",
      "SMC percent accuracy at time 48: 5.600000\n",
      "SMC percent accuracy at time 49: 74.800003\n"
     ]
    }
   ],
   "source": [
    "for t in range(50):\n",
    "    print('SMC percent accuracy at time %d: %f' % (t, accuracy[t].mean(dim=0) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:funcytorch] *",
   "language": "python",
   "name": "conda-env-funcytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
