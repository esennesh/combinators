{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eli/AnacondaProjects/combinators\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import probtorch\n",
    "import torch\n",
    "\n",
    "from examples.fep_control import fep_control\n",
    "from combinators.model import active\n",
    "from combinators.model import compose, foldable\n",
    "from combinators.inference import importance\n",
    "from combinators import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_actor = fep_control.MountainCarActor(state_dim=3, batch_shape=(1,), trainable=False)\n",
    "target_observer = fep_control.GenerativeObserver(observation_dim=2, batch_shape=(1,), trainable=False)\n",
    "target = compose(target_observer, target_actor)\n",
    "\n",
    "proposal_actor = fep_control.RecognitionActor(state_dim=3, action_dim=1, observation_dim=2, batch_shape=(1,),\n",
    "                                              discrete_actions=False, name='MountainCarActor', trainable=True)\n",
    "proposal_encoder = fep_control.RecognitionEncoder(state_dim=3, observation_dim=2, batch_shape=(1,), trainable=True)\n",
    "proposal = compose(proposal_encoder, proposal_actor)\n",
    "\n",
    "agent = importance.propose(target, proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, graph, log_weight = active.active_inference_test(agent, 'MountainCarContinuous-v0', online_inference=False, iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/03/2019 18:03:55 ELBO=-2.84041953e+04 at episode 0 of length 1000\n",
      "06/03/2019 18:04:03 ELBO=-2.21199570e+04 at episode 1 of length 1000\n",
      "06/03/2019 18:04:11 ELBO=-2.21296270e+04 at episode 2 of length 1000\n",
      "06/03/2019 18:04:19 ELBO=-2.14250391e+04 at episode 3 of length 1000\n",
      "06/03/2019 18:04:27 ELBO=-2.04588359e+04 at episode 4 of length 1000\n",
      "06/03/2019 18:04:36 ELBO=-2.01921172e+04 at episode 5 of length 1000\n",
      "06/03/2019 18:04:44 ELBO=-2.38422617e+04 at episode 6 of length 1000\n",
      "06/03/2019 18:04:53 ELBO=-2.01716992e+04 at episode 7 of length 1000\n",
      "06/03/2019 18:05:01 ELBO=-2.03455820e+04 at episode 8 of length 1000\n",
      "06/03/2019 18:05:09 ELBO=-2.01703555e+04 at episode 9 of length 188\n"
     ]
    }
   ],
   "source": [
    "theta, graph, log_weight = active.active_inference(agent, 'MountainCarContinuous-v0', lr=1e-2, episodes=10, episode_length=1000, dream=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-20170.3555], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, graph, log_weight = active.active_inference_test(agent, 'MountainCarContinuous-v0', online_inference=False, iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0317,  0.1386,  0.0600]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[3.1996]], device='cuda:0', grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-10868.5566], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent, 'examples/fep_control/fep_mountain_car_agent.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:funcytorch] *",
   "language": "python",
   "name": "conda-env-funcytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
